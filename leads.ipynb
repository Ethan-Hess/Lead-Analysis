{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import glob, os\n",
    "\n",
    "folder_path = 'D:\\VSCode\\Lead Analysis'\n",
    "# folder_path = 'E:\\Data' # Comment this one out\n",
    "# folder_path = 'E:\\Data\\Python CSV Proccesing Folder' # DELETE POUND SIGN\n",
    "# csv_files = glob.glob(f'{folder_path}/*.csv')\n",
    "csv_files = glob.glob(os.path.join(folder_path, '**', '*.csv'), recursive=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# My counter without different encoding methods\n",
    "leads_breakdown = pd.DataFrame(columns=['Filename', '# of rows', 'Column List'])\n",
    "print(len(csv_files))\n",
    "for file in csv_files:\n",
    "    name = Path(file).name\n",
    "    print(name)\n",
    "    row_count = 0\n",
    "    columns_df = pd.read_csv(file, nrows=0)\n",
    "    columns = columns_df.columns\n",
    "    for chunk in pd.read_csv(file,chunksize=1000000 ,usecols=[0], on_bad_lines='skip'):\n",
    "        row_count += len(chunk)\n",
    "    column_list = ', '.join(columns)\n",
    "    new_row = pd.DataFrame([{'Filename': name, '# of rows': row_count, 'Column List': column_list}])\n",
    "    leads_breakdown = pd.concat([leads_breakdown, new_row], ignore_index=True)\n",
    "    print(f'\\nDone: {row_count}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the DataFrame\n",
    "leads_breakdown = pd.DataFrame(columns=['Filename', '# of rows', 'Column List'])\n",
    "\n",
    "# List of possible encodings to try\n",
    "encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "\n",
    "print(len(csv_files))\n",
    "for file in csv_files:\n",
    "    # Get the filename\n",
    "    name = Path(file).name\n",
    "    \n",
    "    print(name)\n",
    "    row_count = 0\n",
    "    columns = None\n",
    "    \n",
    "    # Try different encodings\n",
    "    for encoding in encodings:\n",
    "        try:\n",
    "            columns_df = pd.read_csv(file, nrows=0, encoding=encoding)\n",
    "            columns = columns_df.columns\n",
    "            break  # If it succeeds, no need to try other encodings\n",
    "        except UnicodeDecodeError:\n",
    "            continue  # Try the next encoding\n",
    "\n",
    "    if columns is None:\n",
    "        print(f\"Failed to decode {name} with available encodings.\")\n",
    "        continue\n",
    "    \n",
    "    # Count rows in chunks\n",
    "    for chunk in pd.read_csv(file, chunksize=1000000, usecols=[0], on_bad_lines='skip', encoding=encoding):\n",
    "        row_count += len(chunk)\n",
    "    \n",
    "    # Create new row with information\n",
    "    column_list = ', '.join(columns)\n",
    "    new_row = pd.DataFrame([{'Filename': name, '# of rows': row_count, 'Column List': column_list}])\n",
    "    leads_breakdown = pd.concat([leads_breakdown, new_row], ignore_index=True)\n",
    "    print(f'\\nDone: {row_count}\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{1: ['D:\\\\VSCode\\\\Lead Analysis\\\\7.6M-US-Business-Leads-Databases-AllStates-csv-2020.csv', 'D:\\\\VSCode\\\\Lead Analysis\\\\Output\\\\lead_analysis.csv', 'D:\\\\VSCode\\\\Lead Analysis\\\\Output\\\\plumb_list.csv']}\n",
      "{1: ['D:\\\\VSCode\\\\Lead Analysis\\\\7.6M-US-Business-Leads-Databases-AllStates-csv-2020.csv', 'D:\\\\VSCode\\\\Lead Analysis\\\\Output\\\\lead_analysis.csv', 'D:\\\\VSCode\\\\Lead Analysis\\\\Output\\\\plumb_list.csv']}\n",
      "<class 'dict'>\n",
      "Current File: D:\\VSCode\\Lead Analysis\\7.6M-US-Business-Leads-Databases-AllStates-csv-2020.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\3than\\AppData\\Local\\Temp\\ipykernel_6928\\2080574269.py:43: DtypeWarning: Columns (5,21,22,23,24,25,26,27,28,29,30,31) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  for chunk in pd.read_csv(file, chunksize=1000000, on_bad_lines='skip', encoding=encoding):\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 55\u001b[0m\n\u001b[0;32m     53\u001b[0m greg[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m=\u001b[39m csv_files\n\u001b[0;32m     54\u001b[0m \u001b[38;5;28mprint\u001b[39m(greg)\n\u001b[1;32m---> 55\u001b[0m \u001b[43mchunk_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgreg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# inclusive\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m, in \u001b[0;36mchunk_search\u001b[1;34m(file_list, chunk_start, chunk_end)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(file, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding):\n\u001b[1;32m---> 44\u001b[0m         result \u001b[38;5;241m=\u001b[39m chunk[\u001b[43mchunk\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplumb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43many\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m]\n\u001b[0;32m     45\u001b[0m         search_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([search_results, result], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# If it succeeds, no need to try other encodings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\frame.py:10374\u001b[0m, in \u001b[0;36mDataFrame.apply\u001b[1;34m(self, func, axis, raw, result_type, args, by_row, engine, engine_kwargs, **kwargs)\u001b[0m\n\u001b[0;32m  10360\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapply\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m frame_apply\n\u001b[0;32m  10362\u001b[0m op \u001b[38;5;241m=\u001b[39m frame_apply(\n\u001b[0;32m  10363\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10364\u001b[0m     func\u001b[38;5;241m=\u001b[39mfunc,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10372\u001b[0m     kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[0;32m  10373\u001b[0m )\n\u001b[1;32m> 10374\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mapply\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:916\u001b[0m, in \u001b[0;36mFrameApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    913\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mraw:\n\u001b[0;32m    914\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_raw(engine\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine, engine_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine_kwargs)\n\u001b[1;32m--> 916\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_standard\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1063\u001b[0m, in \u001b[0;36mFrameApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply_standard\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m   1062\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpython\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m-> 1063\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mapply_series_generator\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1064\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1065\u001b[0m         results, res_index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_series_numba()\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\apply.py:1081\u001b[0m, in \u001b[0;36mFrameApply.apply_series_generator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1078\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m option_context(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode.chained_assignment\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   1079\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, v \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(series_gen):\n\u001b[0;32m   1080\u001b[0m         \u001b[38;5;66;03m# ignore SettingWithCopy here in case the user mutates\u001b[39;00m\n\u001b[1;32m-> 1081\u001b[0m         results[i] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1082\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(results[i], ABCSeries):\n\u001b[0;32m   1083\u001b[0m             \u001b[38;5;66;03m# If we have a view on v, we need to make a copy because\u001b[39;00m\n\u001b[0;32m   1084\u001b[0m             \u001b[38;5;66;03m#  series_generator will swap out the underlying data\u001b[39;00m\n\u001b[0;32m   1085\u001b[0m             results[i] \u001b[38;5;241m=\u001b[39m results[i]\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 44\u001b[0m, in \u001b[0;36mchunk_search.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     42\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     43\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mread_csv(file, chunksize\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1000000\u001b[39m, on_bad_lines\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mskip\u001b[39m\u001b[38;5;124m'\u001b[39m, encoding\u001b[38;5;241m=\u001b[39mencoding):\n\u001b[1;32m---> 44\u001b[0m         result \u001b[38;5;241m=\u001b[39m chunk[chunk\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: \u001b[43mrow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mastype\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcontains\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mplumb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39many(), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)]\n\u001b[0;32m     45\u001b[0m         search_results \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([search_results, result], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     46\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m  \u001b[38;5;66;03m# If it succeeds, no need to try other encodings\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:137\u001b[0m, in \u001b[0;36mforbid_nonstring_types.<locals>._forbid_nonstring_types.<locals>.wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    132\u001b[0m     msg \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot use .str.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m with values of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    134\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferred dtype \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_inferred_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    135\u001b[0m     )\n\u001b[0;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[1;32m--> 137\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:1336\u001b[0m, in \u001b[0;36mStringMethods.contains\u001b[1;34m(self, pat, case, flags, na, regex)\u001b[0m\n\u001b[0;32m   1328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m   1329\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis pattern is interpreted as a regular expression, and has \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1330\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmatch groups. To actually get the groups, use str.extract.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   1331\u001b[0m         \u001b[38;5;167;01mUserWarning\u001b[39;00m,\n\u001b[0;32m   1332\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m   1333\u001b[0m     )\n\u001b[0;32m   1335\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data\u001b[38;5;241m.\u001b[39marray\u001b[38;5;241m.\u001b[39m_str_contains(pat, case, flags, na, regex)\n\u001b[1;32m-> 1336\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_wrap_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mna\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturns_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\strings\\accessor.py:406\u001b[0m, in \u001b[0;36mStringMethods._wrap_result\u001b[1;34m(self, result, name, expand, fill_value, returns_string, returns_bool, dtype)\u001b[0m\n\u001b[0;32m    403\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    404\u001b[0m     \u001b[38;5;66;03m# Must be a Series\u001b[39;00m\n\u001b[0;32m    405\u001b[0m     cons \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_orig\u001b[38;5;241m.\u001b[39m_constructor\n\u001b[1;32m--> 406\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mcons\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_dtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    407\u001b[0m result \u001b[38;5;241m=\u001b[39m result\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_orig, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstr\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    408\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m result\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m    409\u001b[0m     \u001b[38;5;66;03m# __finalize__ might copy over the original name, but we may\u001b[39;00m\n\u001b[0;32m    410\u001b[0m     \u001b[38;5;66;03m# want the new name (e.g. str.extract).\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\series.py:592\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    589\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    590\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleArrayManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index)\n\u001b[1;32m--> 592\u001b[0m \u001b[43mNDFrame\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    593\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n\u001b[0;32m    594\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_set_axis(\u001b[38;5;241m0\u001b[39m, index)\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\generic.py:283\u001b[0m, in \u001b[0;36mNDFrame.__init__\u001b[1;34m(self, data)\u001b[0m\n\u001b[0;32m    281\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_item_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[0;32m    282\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_attrs\u001b[39m\u001b[38;5;124m\"\u001b[39m, {})\n\u001b[1;32m--> 283\u001b[0m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__setattr__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_flags\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[43mFlags\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallows_duplicate_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m)\n",
      "File \u001b[1;32mc:\\Users\\3than\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pandas\\core\\flags.py:53\u001b[0m, in \u001b[0;36mFlags.__init__\u001b[1;34m(self, obj, allows_duplicate_labels)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj: NDFrame, \u001b[38;5;241m*\u001b[39m, allows_duplicate_labels: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allows_duplicate_labels \u001b[38;5;241m=\u001b[39m allows_duplicate_labels\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obj \u001b[38;5;241m=\u001b[39m \u001b[43mweakref\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "encodings = ['utf-8', 'latin1', 'iso-8859-1', 'cp1252']\n",
    "keyword = 'plumb'\n",
    "\n",
    "chunk_division = range(15)\n",
    "temp_files = list(range(500))\n",
    "csv_chunk_size = 1000000\n",
    "filtered_chunks = []\n",
    "folder_path = 'D:\\VSCode\\Lead Analysis'\n",
    "csv_files = glob.glob(os.path.join(folder_path, '**', '*.csv'), recursive=True)\n",
    "\n",
    "def chunk_files(file_list): # Equally divides the list based off of chunk size\n",
    "    files_per_chunk = int(len(file_list) / len(chunk_division))\n",
    "    chunk = {}\n",
    "    x = 0\n",
    "    for i in chunk_division:\n",
    "        y = x + files_per_chunk if i < max(chunk_division) else len(file_list)\n",
    "        chunk[f'{i}'] = file_list[x:y]\n",
    "        x = y\n",
    "    return chunk\n",
    "\n",
    "def chunk_search(file_list:dict, chunk_start, chunk_end):\n",
    "    search_results = pd.DataFrame()\n",
    "    processing_list = {}\n",
    "\n",
    "    # inclusive range of file index\n",
    "    if chunk_start == chunk_end:\n",
    "        processing_list = file_list\n",
    "    else:\n",
    "        processing_range = range(chunk_start, chunk_end + 1)\n",
    "        for i in processing_range:\n",
    "            print(i)\n",
    "            processing_list[f'{i}'] = file_list[f'{i}']\n",
    "    print(file_list)\n",
    "    print(type(processing_list))\n",
    "\n",
    "\n",
    "    for index, files in processing_list.items():\n",
    "        for file in files:\n",
    "            print(f'Current File: {file}')\n",
    "            for encoding in encodings:\n",
    "                try:\n",
    "                    for chunk in pd.read_csv(file, chunksize=1000000, on_bad_lines='skip', encoding=encoding):\n",
    "                        result = chunk[chunk.apply(lambda row: row.astype(str).str.contains('plumb').any(), axis=1)]\n",
    "                        search_results = pd.concat([search_results, result], ignore_index=True)\n",
    "                    break  # If it succeeds, no need to try other encodings\n",
    "                except UnicodeDecodeError:\n",
    "                    continue  # Try the next encoding\n",
    "\n",
    "    search_results.to_csv('Output\\plumb_list.csv', index=False) #16.49 to search whole dataset\n",
    "\n",
    "greg = {}\n",
    "greg[1] = csv_files\n",
    "print(greg)\n",
    "chunk_search(greg, 1, 1) # inclusive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "leads_breakdown.to_csv('Output\\lead_analysis.csv', index=False)\n",
    "leads_breakdown.to_csv('Output\\lead_plumb.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2063 prev set                                                                                                                            Click execute above cells ^"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
